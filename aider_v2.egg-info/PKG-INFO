Metadata-Version: 2.4
Name: aider-v2
Version: 2.0.0
Summary: Aider v2 - AI pair programming with improved architecture
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: typer>=0.16.0
Requires-Dist: rich>=14.0.0
Requires-Dist: prompt-toolkit>=3.0.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: gitpython>=3.1.0
Requires-Dist: openai>=1.0.0
Requires-Dist: anthropic>=0.25.0
Requires-Dist: litellm>=1.0.0
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: pathspec>=0.11.0
Requires-Dist: tree-sitter>=0.20.0
Requires-Dist: pygments>=2.15.0
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: toml>=0.10.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-mock>=3.10.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: isort>=5.12.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"

# Aider v2 - AI Pair Programming Assistant

Aider v2 is a complete architectural rewrite of the original Aider, featuring a clean, modular design with improved maintainability, testability, and extensibility.

## ğŸš€ Key Improvements

### Architecture Benefits
- **Modular Design**: Clean separation of concerns with interfaces and dependency injection
- **Testable**: Easy to unit test with mocked dependencies
- **Extensible**: Plugin system for adding new LLM providers and coders
- **Maintainable**: Smaller, focused files with single responsibilities

### Technical Improvements
- **Type Safety**: Full type hints throughout the codebase
- **Error Handling**: Robust error handling with custom exceptions
- **Logging**: Comprehensive logging for debugging and monitoring
- **Configuration**: Flexible configuration system with file and environment support

## ğŸ“ Project Structure

```
aider_v2/
â”œâ”€â”€ core/                    # Core business logic
â”‚   â”œâ”€â”€ interfaces/          # Abstract interfaces
â”‚   â”œâ”€â”€ domain/             # Domain models
â”‚   â”œâ”€â”€ services/           # Business services
â”‚   â””â”€â”€ container.py        # Dependency injection
â”œâ”€â”€ infrastructure/         # External integrations
â”‚   â”œâ”€â”€ llm/               # LLM provider implementations
â”‚   â”œâ”€â”€ coders/            # Code editing implementations
â”‚   â””â”€â”€ repository/        # Repository implementations
â”œâ”€â”€ ui/                     # User interface layer
â”‚   â”œâ”€â”€ cli/               # Command-line interface
â”‚   â””â”€â”€ terminal/          # Terminal UI implementation
â”œâ”€â”€ utils/                  # Utility functions
â””â”€â”€ config/                # Configuration management
```

## ğŸ›  Installation

```bash
# Clone the repository
git clone <repository-url>
cd aider_v2

# Install dependencies
pip install -e .

# Or install with development dependencies
pip install -e ".[dev]"
```

## ğŸ”§ Configuration

### Environment Variables
```bash
export OPENAI_API_KEY="your-openai-api-key"
export ANTHROPIC_API_KEY="your-anthropic-api-key"
export AIDER_MODEL="gpt-4o"
export AIDER_PROVIDER="openai"
```

### Configuration File
Create `.aider.toml` in your project directory:

```toml
[llm]
provider = "openai"
model = "gpt-4o"
temperature = 0.7

[coder]
type = "editblock"
auto_apply = false
show_diffs = true

[repository]
auto_commit = true
commit_message_template = "AI: {description}"

[ui]
theme = "monokai"
syntax_highlighting = true
confirm_changes = true
```

## ğŸš€ Usage

### Basic Usage
```bash
# Start Aider in current directory
aider-v2

# Specify model and provider
aider-v2 --model gpt-4o --provider openai

# Add files to initial context
aider-v2 --files src/main.py src/utils.py

# Enable verbose logging
aider-v2 --verbose
```

### Commands
```bash
/add <file>      # Add files to context
/files           # Show files in context
/clear           # Clear context
/status          # Show git status
/diff <file>     # Show file diff
/history         # Show commit history
/help            # Show help
/exit            # Exit application
```

### Example Session
```
ğŸ¤– Aider v2 - AI Pair Programming Assistant

> /add src/calculator.py
âœ… Added 1 files to context

> Add error handling to the divide function

I'll add proper error handling to the divide function to handle division by zero.

calculator.py
<<<<<<< SEARCH
def divide(a, b):
    return a / b
=======
def divide(a, b):
    if b == 0:
        raise ValueError("Cannot divide by zero")
    return a / b
>>>>>>> REPLACE

Apply these changes? (y/N): y
âœ… Changes applied and committed: a1b2c3d4
```

## ğŸ— Architecture Overview

### Core Interfaces
- **ICoder**: Defines contract for code editing implementations
- **ILLMProvider**: Abstracts different LLM providers (OpenAI, Anthropic)
- **IRepository**: Handles version control and file operations
- **IUserInterface**: Abstracts different UI implementations

### Dependency Injection
The application uses a simple dependency injection container to manage service dependencies:

```python
from aider_v2.core.container import container

# Register services
container.register(ILLMProvider, OpenAIProvider)
container.register(ICoder, EditBlockCoder)

# Get services with automatic dependency resolution
chat_service = container.get(ChatService)
```

### Plugin System
Easy to extend with new providers and coders:

```python
# Add new LLM provider
class CustomLLMProvider(ILLMProvider):
    def generate_response(self, messages, model, config=None):
        # Implementation
        pass

# Register the provider
container.register(ILLMProvider, CustomLLMProvider)
```

## ğŸ§ª Testing

```bash
# Run tests
pytest

# Run with coverage
pytest --cov=aider_v2

# Run specific test file
pytest tests/test_chat_service.py
```

### Test Structure
```
tests/
â”œâ”€â”€ unit/                   # Unit tests
â”‚   â”œâ”€â”€ test_chat_service.py
â”‚   â”œâ”€â”€ test_coders.py
â”‚   â””â”€â”€ test_llm_providers.py
â”œâ”€â”€ integration/            # Integration tests
â”‚   â””â”€â”€ test_full_workflow.py
â””â”€â”€ fixtures/              # Test fixtures
```

## ğŸ”Œ Extending Aider v2

### Adding a New LLM Provider
1. Implement the `ILLMProvider` interface
2. Register it in the container
3. Add configuration options

### Adding a New Coder
1. Implement the `ICoder` interface
2. Handle your specific edit format
3. Register it in the container

### Adding New Commands
1. Add command handler in `cli/commands.py`
2. Update help text
3. Add tests

## ğŸ“Š Comparison with Original Aider

| Aspect | Original Aider | Aider v2 |
|--------|---------------|----------|
| Architecture | Monolithic | Modular/Layered |
| File Size | 2,485 lines (base_coder.py) | ~300 lines max per file |
| Testing | Difficult (tight coupling) | Easy (dependency injection) |
| Extensibility | Hard to extend | Plugin system |
| Type Safety | Partial | Full type hints |
| Error Handling | Basic | Comprehensive |

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“ License

[License information]

## ğŸ™ Acknowledgments

- Original Aider project for inspiration
- Rich library for beautiful terminal output
- Click for CLI framework
